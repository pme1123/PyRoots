{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Parameters for Frangi Vessel Enhancement-based Segmentation\n",
    "\n",
    "This is the preferred method for dirty images, though computationally it is a bit more expensive than than the thresholding based method. \n",
    "\n",
    "Use this script to make decisions about critical parameters based on the images you capture. Base this on 5-10 images that have the characteristics of:\n",
    "- Similar, representative color profile\n",
    "- Variety of challenges. For hyphae detection, this includes: dirty areas, hyphae-like objects (skinny, long, but unstained), fat objects, blurry/thin hyphae, etc.\n",
    "\n",
    "Then, either:\n",
    "- Update an `frangi_segmentation_analysis.py` script for your image loop. \n",
    "- Run `frangi_image_loop()` at the end of this notebook.\n",
    "\n",
    "The image loop function saves a dataframe to a .CSV with columns:\n",
    "- Image: Identifier of each image\n",
    "- NObjects: Number of individual objects measured in Image (without diameter binning)\n",
    "- Diameter: Mean diameter of all objects in Image(in pixels)\n",
    "- Length: Total length of all objects in Image (in pixels)\n",
    "Alternatively, objects can be binned by diameter class. This returns a dataframe specifying length by diameter class, using similarly intuitive column names. \n",
    "\n",
    "## Steps\n",
    "1. Load images and libraries\n",
    "2. Equalize exposure\n",
    "3. View candidate colorspace bands\n",
    "4. Pull the band of interest\n",
    "5. Enhance vessels with the frangi filter\n",
    "6. Adaptive threshold to segment frangi filter\n",
    "7. Filter based on color\n",
    "8. Filter based on geometry\n",
    "9. Filter based on hollowness\n",
    "10. Combine filters and check results\n",
    "11. Remove small holes and close small gaps\n",
    "12. Fun another, more stringent geometry filter\n",
    "13. Skeletonize\n",
    "14. Summarize\n",
    "15. Export parameters\n",
    "16. Test full analysis for stability\n",
    "17. Run loop\n",
    "\n",
    "## 1. Load images and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: AW1-0437.png\n",
      "Image Dimensions [length, width, bands]: [1741, 1741, 3]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#########################################################################################\n",
    "dir_in = \"/home/patrick/Documents/HLD Pictures Feb 2017/image filtered/02-06-2017/Processed_No_Smoothing\"\n",
    "file_in = [\"AU1-0042.png\", \"BF2-2131.png\", \"BF2-2158.png\", \"AU1-0059.png\", \"BF2-2163.png\", \n",
    "           \"AV2-0311.png\", \"AW1-0437.png\", \"AW1-0462.png\", \"AW1-0476.png\", \"BD1-1712.png\",\n",
    "           \"AU1-0032.png\", \"AU1-0021.png\"]\n",
    "\n",
    "# what do you want to work on for the moment? Select the image index from file_in.\n",
    "selection = 6\n",
    "\n",
    "# Zoom to these bounding boxes for easy viewing.\n",
    "zoom_topleft =     {'xmin' : 300,\n",
    "                    'xmax' : 1000,\n",
    "                    'ymin' : 0,\n",
    "                    'ymax' : 700}\n",
    "zoom_topright =    {'xmin' : 1000,\n",
    "                    'xmax' : 1700,\n",
    "                    'ymin' : 0,\n",
    "                    'ymax' : 700}\n",
    "zoom_bottomleft =  {'xmin' : 0,\n",
    "                    'xmax' : 700,\n",
    "                    'ymin' : 1000,\n",
    "                    'ymax' : 1700}\n",
    "zoom_bottomright = {'xmin' : 1040,\n",
    "                    'xmax' : 1740,\n",
    "                    'ymin' : 1040,\n",
    "                    'ymax' : 1740}\n",
    "zoom_center=       {'xmin' : 1000,\n",
    "                    'xmax' : 1700,\n",
    "                    'ymin' : 600,\n",
    "                    'ymax' : 1300}\n",
    "plot = True\n",
    "plot = False\n",
    "#########################################################################################\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import io, color, filters, draw, morphology, exposure, img_as_float, img_as_ubyte, restoration, measure\n",
    "import pyroots as pr\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "image = io.imread(os.path.join(dir_in, file_in[selection]))\n",
    "\n",
    "print(\"Image: \" + file_in[selection] + \"\\nImage Dimensions [length, width, bands]: \" + str([i for i in image.shape]))\n",
    "\n",
    "if plot is True:\n",
    "    img = image\n",
    "    plt.imshow(img)\n",
    "    zoom_list = [zoom_topleft, zoom_topright, zoom_bottomleft, zoom_bottomright, zoom_center]\n",
    "    zoom_names = ['Top Left', 'Top Right', 'Bottom Left', 'Bottom Right', 'Center']\n",
    "    pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list], zoom_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Select the band of the colorspace for identifying candidate objects\n",
    "Choose a band that shows hyphae clearly and consistently. Some distinction between hyphae and non-hyphae objects helps but is not essential. Objects should not be partly outlined in higher (lighter) values; for this reason, avoid chroma type bands like hue of hsv or a\\* and b\\* of l\\*a\\*b\\*. For analine blue stain in a microscope, the red band of rgb is good. \n",
    "\n",
    "In general, a single band is sufficient for identifying candidate objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "colorspaces = ['rgb','hsv','lab','xyz','luv', 'hed'] # add or remove whatever you're curious about. See skimage.color.rgb2*()\n",
    "colorspace_zoom = zoom_center\n",
    "####################################################\n",
    "bandviewer=True\n",
    "bandviewer = False\n",
    "if bandviewer is True: [pr.band_viewer(image, i, colorspace_zoom) for i in colorspaces]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pull out the band of interest\n",
    "Identify the colorspace and band that seems to show objects clearly, while also highlighting differences from non-objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "colors = {'colorspace' : 'rgb',\n",
    "          'band'       : 0,      # rgb: 0 = red, 1 = green, 2 = blue\n",
    "          'invert'     : False}  # True for light objects on dark background\n",
    "#########################################################################################\n",
    "\n",
    "# convert colorspace if necessary\n",
    "if colors['colorspace'].lower() != 'rgb':\n",
    "    band = getattr(color, \"rgb2\" + colors['colorspace'])(image)\n",
    "else:\n",
    "    band = image.copy()\n",
    "    \n",
    "if colors['invert'] == True:\n",
    "    band = 1 - img_as_float(band)\n",
    "    \n",
    "band = pr.img_split(band)[colors['band']]\n",
    "img = band\n",
    "if plot is True: pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list], zoom_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run frangi filter\n",
    "\n",
    "The frangi filter enhances ridges/edges of a series of widths and set contrast from neighboring objects. Width is controlled by `sigma`, dictated by `scale_range` and `scale_step`. Sensitivity is controlled by `beta2`. See <a href=\"http://scikit-image.org/docs/dev/api/skimage.filters.html\"> documentation</a>.\n",
    "\n",
    "Pick a `scale_range` that highlights whole hyphae and edges of larger objects. For hyphae at 100x, a scale range of `(2, 8)` works well. `scale_step` should sufficiently cover width classes. `beta1` should be nearly 1 for best behavior. `beta2` controls the sensitivity, and should be set so that objects are clear, and touching objects have an area of lower response between them. The value probably will be close to 0.05. Expect lots of spurrious, small objects that will be removed with further filtering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "frangi_args = {'scale_range'  : (2, 6),  # sigmas for running the filter. Wider enhances wider objects; narrow enhances narrow objects.\n",
    "               'scale_step'   : 1,       # step between sigmas in the scale range.\n",
    "               'beta1'        : 0.99,    # correction [0,1] toward linear vs ring-like. Want close to 1.\n",
    "               'beta2'        : 0.03,    # sensitivity to low-contrast areas. Smaller is more sensitive.\n",
    "               'black_ridges' : True}    # dark objects on light background? Suggest inverting with colors and holding this True.\n",
    "#########################################################################################\n",
    "\n",
    "\n",
    "frangi = filters.frangi(band, **frangi_args)  # detect black or white ridges\n",
    "\n",
    "if plot is True:\n",
    "    print(frangi.max())\n",
    "    print(frangi.min())\n",
    "    img = frangi\n",
    "    pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list], zoom_names)\n",
    "    # img = rescaled[0] > np.percentile(rescaled[0], 98)\n",
    "    img = band\n",
    "    pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list], zoom_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Adaptive threshold the frangi filter\n",
    "Now identify objects and edges using an adaptive threshold. The advantage of this is, it separates distinct objects from each other due to their combined high response giving a locally high thresholed. For it to work, the sensitivity of the frangi filter must be low enough to give low responses where objects touch. \n",
    "\n",
    "Strategy:\n",
    "* `block_size` : Defines the local neighborhood for thresholding. Should be small enough to be responsive to the local neighborhood, but large enough to avoid splitting wider objects. For frangi vessel range of [2:8], a `block_size` of 29 is good.\n",
    "* `offset` : Sets the threshold for the area. Range [0:1] for float images like these. Highly sensitive. The ideal value proably will be between 0.05 and 0.1.\n",
    "\n",
    "The image shows separate colors for each individual object (via `scipy.ndimage.label`). Use this to evaluate connectivity among objects. See <a href=\"http://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.threshold_adaptive\"> documentation</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "threshold_args = {'block_size' : 31,  # small enough to respond strongly to the local neighborhood, large enough to avoid hollowing objects\n",
    "                  'offset'     : 0.22}  # high enough to separate touching objects, but low enough to maintain connectivity\n",
    "#########################################################################################\n",
    "\n",
    "thresh = 1 - (frangi/frangi.max())  # invert, rescale so vessels are dark.\n",
    "thresh = ~filters.threshold_adaptive(thresh, **threshold_args)  # invert so objects are True\n",
    "\n",
    "if plot is True:\n",
    "    img = ndimage.label(thresh)[0]\n",
    "    pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list], zoom_names, color_map = \"spectral\")\n",
    "    img = band\n",
    "    pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list], zoom_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Filter objects by color values\n",
    "If staining, objects should be a consistent color if not a consistent saturation. This provides a way of distinguishing real objects from spurrious ones. The algorithm determines whether each pixel of a band array falls within range, then computes the area of those pixels within an object meets a minimum percent of the total area of each object. See <a href=\"https://github.com/pme1123/pyroots/blob/master/pyroots/noise_filters.py\"> documentation</a>. If working with a grayscale image or want to feed the band manually, choose `grayscale_filter` instead of `color_filter`. \n",
    "\n",
    "Strategy:\n",
    "1. Choose a `target_band` from a `colorspace` where real objects and false objects don't overlap too much. For the example image, I chose blue in RGB and saturation in HSV.\n",
    "2. Determine the `low` and `high` range of values that real objects should take.\n",
    "3. Set a minimum `percent` of pixels in an object that should be within this value range. \n",
    "\n",
    "These thresholds will not be perfect, so set them to give a little wiggle room. We're particularly interested in large objects that are linear, like hyphae. Test for sensitivity. It might be helpful to look at thresholded images where the threshold is set too high (oversegmentation). \n",
    "\n",
    "To help set bounds, these code blocks print 0.5%, 50%, and 99.5% values as well as band values with a spectral key. The 50% value should be the background, with lower and higher values denoted by blue and red, respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Filter 1\n",
    "Blue in RGB: \n",
    "Background has a very high value; true objects have a moderate-high value; dirt and such has a low value. I chose parameters to allow a little wiggle (+/- 0.1 direction for `low`, `high`, +/- 5 `percent`) without changing true objects acceptance. Note that objects that look like hyphae but aren't (long, solid, thin) are the most important to remove. Small, hollow, and rounder objects will be removed later. \n",
    "\n",
    "The values I chose for Blue in RGB remove much of the top left false objects, but fail to remove the quarter circle in the top right. They do, however, preserve all true hyphae. Note that you can also select objects that you want to remove, by inverting the color filter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "color_args_1 = {'colorspace'  : 'rgb',  # Colorspace from which to select band\n",
    "                'target_band' : 2,      # Band of colorspace\n",
    "                'low'         : 0.6,    # minimum of range for color value (as float, passes to pyroots._in_range uses)\n",
    "                'high'        : 0.99,   # maximum of range for color value\n",
    "                'percent'     : 55,     # minimum percent of all pixels that must fall with the range\n",
    "                'invert'      : False}  # Are you selecting objects you want to remove?\n",
    "# color_args_1 = None\n",
    "colorargs = color_args_1  # update this when you add new bands. Suggest naming sequentially.\n",
    "\n",
    "# run_on = morph_filt\n",
    "run_on = thresh\n",
    "#########################################################################################\n",
    "\n",
    "# for viewing\n",
    "try:\n",
    "    colorband = getattr(color, 'rgb2' + colorargs['colorspace'])(image)\n",
    "except:\n",
    "    colorband = image.copy()\n",
    "    colorband = img_as_float(pr.img_split(colorband)[colorargs['target_band']])\n",
    "\n",
    "try:\n",
    "    colorfilt = pr.color_filter(image, run_on, **colorargs)  # image is the original input image\n",
    "except:\n",
    "    colorfilt = np.ones(run_on.shape)\n",
    "\n",
    "####### Update this, as well, for multiple bands\n",
    "colorfilt1 = colorfilt.copy()  # image is the original input image4\n",
    "\n",
    "if plot is True:\n",
    "    if colorargs is not None:\n",
    "        print(\"99.9: {}\".format(np.percentile(colorband, 99.9)))\n",
    "        print('99.5%: ' + str(np.percentile(colorband, 99.5)))\n",
    "        print('50%: ' + str(np.percentile(colorband, 50)))\n",
    "        print('0.5%: ' + str(np.percentile(colorband, 0.5)))\n",
    "        print('\\nFILTERED OBJECTS')\n",
    "        temp = colorband.copy()\n",
    "        temp[~colorfilt] = 0\n",
    "        img = temp\n",
    "        pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list], zoom_names, color_map=\"spectral\")\n",
    "        print('BAND (low is blue; high is red; rescaled for each facet)')\n",
    "        img = colorband\n",
    "        pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list], zoom_names, color_map=\"spectral\")\n",
    "        print('ORIGINAL OBJECTS')\n",
    "        temp = colorband.copy()\n",
    "        temp[~thresh] = 0\n",
    "        img = temp\n",
    "        pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list], zoom_names, color_map=\"spectral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Filter 2\n",
    "Saturation in HSV: Background and objects have high values; objects have relatively low values but variability is large.\n",
    "Based on the previous color filter, choose objects that you want to remove that would be difficult to remove with morphology filtering. Note you can also invert, to 'keep' objects that you want to remove. \n",
    "\n",
    "Again, tolerance is +/-5 `percent` and +/- 0.01 `low` and `high`. \n",
    "\n",
    "I did lose a small piece of hyphae in the top right; this very faint bit is acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "color_args_2 = {'colorspace'  : 'hsv',  # Colorspace from which to select band\n",
    "                'target_band' : 1,      # Band of colorspace\n",
    "                'low'         : 0.5,    # minimum of range for color value\n",
    "                'high'        : 0,   # maximum of range for color value\n",
    "                'percent'     : 30,    # minimum percent of all pixels that must fall with the range\n",
    "                'invert'      : True}  # selecting objects I don't want to keep. \n",
    "# color_args_2 = None\n",
    "\n",
    "run_on = thresh\n",
    "# run_on = morph_filt\n",
    "\n",
    "colorargs = color_args_2  # update this when you add new bands. Suggest naming sequentially.\n",
    "#########################################################################################\n",
    "\n",
    "# for viewing\n",
    "try:\n",
    "    colorband = getattr(color, 'rgb2' + colorargs['colorspace'])(image)\n",
    "except:\n",
    "    colorband = image.copy()\n",
    "    colorband = img_as_float(pr.img_split(colorband)[colorargs['target_band']])\n",
    "\n",
    "try:\n",
    "    colorfilt = pr.color_filter(image, run_on, **colorargs)  # image is the original input image\n",
    "except:\n",
    "    colorfilt = np.ones(run_on.shape)\n",
    "\n",
    "####### Update this, as well, for multiple bands\n",
    "colorfilt2 = colorfilt.copy()  # image is the original input image4\n",
    "\n",
    "if plot is True:\n",
    "    if colorargs is not None:\n",
    "        print(\"99.9: {}\".format(np.percentile(colorband, 99.9)))\n",
    "        print('99.5%: ' + str(np.percentile(colorband, 99.5)))\n",
    "        print('50%: ' + str(np.percentile(colorband, 50)))\n",
    "        print('0.5%: ' + str(np.percentile(colorband, 0.5)))\n",
    "        print('\\nFILTERED OBJECTS')\n",
    "        temp = colorband.copy()\n",
    "        temp[colorfilt] = 0\n",
    "        img = temp\n",
    "        pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list], zoom_names, color_map=\"spectral\")\n",
    "        print('BAND (low is blue; high is red; rescaled for each facet)')\n",
    "        img = colorband\n",
    "        pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list], zoom_names, color_map=\"spectral\")\n",
    "        print('ORIGINAL OBJECTS')\n",
    "        temp = colorband.copy()\n",
    "        temp[~thresh] = 0\n",
    "        img = temp\n",
    "        pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list], zoom_names, color_map=\"spectral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Filter 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "color_args_3 = {'colorspace'  : 'hsv',  # Colorspace from which to select band\n",
    "                'target_band' : 0,      # Band of colorspace\n",
    "                'low'         : 0.450,    # minimum of range for color value\n",
    "                'high'        : 0.7,   # maximum of range for color value\n",
    "                'percent'     : 40,    # minimum percent of all pixels that must fall with the range\n",
    "                'invert'      : False}  # selecting objects I don't want to keep. \n",
    "# color_args_3 = None\n",
    "\n",
    "run_on = thresh\n",
    "# run_on = morph_filt\n",
    "\n",
    "colorargs = color_args_3  # update this when you add new bands. Suggest naming sequentially.\n",
    "#########################################################################################\n",
    "\n",
    "# for viewing\n",
    "try:\n",
    "    colorband = getattr(color, 'rgb2' + colorargs['colorspace'])(image)\n",
    "except:\n",
    "    colorband = image.copy()\n",
    "\n",
    "try:\n",
    "    colorband = img_as_float(pr.img_split(colorband)[colorargs['target_band']])\n",
    "except:\n",
    "    colorband = np.ones(run_on.shape)\n",
    "\n",
    "try:\n",
    "    colorfilt = pr.color_filter(image, run_on, **colorargs)  # image is the original input image\n",
    "except:\n",
    "    colorfilt = np.ones(run_on.shape)\n",
    "\n",
    "####### Update this, as well, for multiple bands\n",
    "colorfilt3 = colorfilt  # image is the original input image\n",
    "\n",
    "if plot is True:\n",
    "    if colorargs is not None:\n",
    "        print(\"99.9: {}\".format(np.percentile(colorband, 99.9)))\n",
    "        print('99.5%: ' + str(np.percentile(colorband, 99.5)))\n",
    "        print('50%: ' + str(np.percentile(colorband, 50)))\n",
    "        print('0.5%: ' + str(np.percentile(colorband, 0.5)))\n",
    "        print('\\nFILTERED OBJECTS')\n",
    "        temp = colorband.copy()\n",
    "        temp[~colorfilt] = 0\n",
    "        img = temp\n",
    "        pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list], zoom_names, color_map=\"spectral\")\n",
    "        print('BAND (low is blue; high is red; rescaled for each facet)')\n",
    "        img = colorband\n",
    "        pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list], zoom_names, color_map=\"spectral\")\n",
    "        print('ORIGINAL OBJECTS')\n",
    "        temp = colorband.copy()\n",
    "        temp[~thresh] = 0\n",
    "        img = temp\n",
    "        pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list], zoom_names, color_map=\"spectral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colorfilt = colorfilt1 * colorfilt2 * colorfilt3  # if changed, change in frangi_analysis script.\n",
    "img = ndimage.label(colorfilt)[0]\n",
    "if plot is True: pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list], zoom_names, color_map=\"spectral\")\n",
    "img = image\n",
    "if plot is True: pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list], zoom_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Filtering based on morphology\n",
    "This filter removes objects based on the properties of the convex hull, and also of ellipses that have equivalent second moments to the convex hull. The properties are:\n",
    "* eccentricity: of an ellipse with equivalent moments to the object's convex hull. Should be very high, since hyphae are mostly long and skinny.\n",
    "* solidity: Percentage of convex hull's area that an object take up. Should be low, since hyphae are curvy and skinny. \n",
    "* major axis length: of ellipse with equivalent moments to convex hull. \n",
    "* area: in pixels of each object.\n",
    "\n",
    "Eccentricity and solidity are combined into levels of filters:\n",
    "1. A 'strict' filter, with stringent eccentricity and solidity thresholds. True objects must pass one.\n",
    "2. A 'loose' filter, which sets a maximum stringency and minimum eccentricity. True objects must pass both. \n",
    "\n",
    "Set the values to allow leeway. Stricter values will be set later in the process. It is helpful to run it on the thresholded image, rather than the color-filter image, to see how tolerances are important. See <a href=\"https://github.com/pme1123/pyroots/blob/master/pyroots/geometry_filters.py\"> documentation</a>.\n",
    "\n",
    "Long, skinny, but hollow objects will be removed with the next filter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "morphology_args_1 = {'loose_eccentricity'  : 0.4,   # This is a floor.\n",
    "                   'loose_solidity'      : 0.6,   # This is a ceiling.\n",
    "                   'strict_eccentricity' : 0.97,  # Floor.\n",
    "                   'strict_solidity'     : 0.4,   # Ceiling.\n",
    "                   'min_length'          : 100,    # Floor.\n",
    "                   'min_size'            : 100}   # Floor.\n",
    "run_on = thresh  # uncomment to run on the raw objects from the frangi enhancement\n",
    "# run_on = colorfilt  # uncomment to run on the objects filtered by color\n",
    "#########################################################################################\n",
    "\n",
    "morph_filt = pr.morphology_filter(run_on, **morphology_args_1)\n",
    "\n",
    "if plot is True:\n",
    "    img = ndimage.label(morph_filt)[0]\n",
    "    pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list], zoom_names, color_map=\"spectral\")\n",
    "    img = image\n",
    "    pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list], zoom_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Filter by hollowness\n",
    "Some objects are long and skinny and have the right color as true objects, but are not. These include really wide objects that were picked up as edges, clear objects with strong parallel edges, etc. They show up as hollow in binary images, and as a result, can be filtered by the ratio of A to B, where:\n",
    "* A = the medial axis length of the candidate object, similar to the perimeter\n",
    "* B = the medial axis length of the candidate object after filling the open gaps\n",
    "This is a slower function, and so should be performed last in the filtering chain. It uses `skimage.morphology.binary_closing` to fill holes, which is more tolerant to long, skinny holes than `remove_small_holes`. See <a href=\"https://github.com/pme1123/pyroots/blob/master/pyroots/geometry_filters.py\"> documentation</a>.\n",
    "\n",
    "Parameters:\n",
    "* fill_kernel : Dictates how wide of a gap can be filled. True objects can have loops, but usually they are large compared to edges of larger objects. A value of 15 (default) fills spaces up to 30 pixels wide. \n",
    "* threshold : maximum perimiter:filled axis ratio. Solid hyphae should have a ratio close to 1; parallel edges a ratio close to 2. \n",
    "\n",
    "Again, it is helpful to set this on a non-filtered, over- and under-thresholded binary image of candidate objects to set appropriate parameters. The ratio is probably larger than expected, due to some small noise loops being present on some objects (which we will take care of next)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "hollow_args = {'ratio'       : 1.5,  # this is a ceiling\n",
    "               'fill_kernel' : 18}   # radius of disk, in pixels, passed to binary_closing\n",
    "# run_on = thresh      # uncomment to run on the raw objects from the frangi enhancement\n",
    "# run_on = colorfilt   # uncomment to run on the objects filtered by color\n",
    "run_on = morph_filt  # uncomment to run on the objects filtered by morphology.\n",
    "#########################################################################################\n",
    "\n",
    "try:\n",
    "    run_on = morphology.remove_small_holes(run_on, min_size=10)\n",
    "    hollow_filt = pr.hollow_filter(run_on, **hollow_args)\n",
    "    if plot is True:\n",
    "        img = hollow_filt\n",
    "        pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list], zoom_names)\n",
    "        img = ndimage.label(morph_filt)[0]\n",
    "        pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list], zoom_names, color_map = \"spectral\")\n",
    "#         img = [run_on, hollow_filt, image]\n",
    "#         pr.multi_image_plot(img, ['objects', 'filtered', 'image'])\n",
    "except:\n",
    "    print(\"Nothing to Filter\")\n",
    "    hollow_filt = np.ones(thresh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Combine Filters and Check Results.\n",
    "Generally, only keep objects that pass all three filter sets. Did you keep (almost all) of what you wanted, and nothing else? \n",
    "* **If so**: Continue\n",
    "* **If not**: Are the objects you want to ignore close together and parallel? Are they extremely thin? If so, a diameter filter after filling gaps might be helpful. Otherwise, try changing thresholding offsets or frangi sensitivity first. Pay special attention to connectivity of candidate objects in the initial thresholding image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filt = colorfilt * morph_filt * hollow_filt\n",
    "\n",
    "if plot is True:\n",
    "    img = filt\n",
    "    pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list], zoom_names)\n",
    "    img = image\n",
    "    pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list], zoom_names)\n",
    "    img = [filt, image]\n",
    "    pr.multi_image_plot(img, ['objects', 'image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Fill small holes and close small gaps in true objects\n",
    "This step closes small gaps and holes. The gaps underestimate true object length; the holes lead to overestimation. Filling these gaps allows for more stringent geometry filtering; doing this after most filtering reduces real objects from sticking to spurrious objects. Pick parameters that allow most gaps to be filled consistently without joining truely discrete objects too often.\n",
    "\n",
    "Hole filling and gap closing uses `skimage.morphology.binary_closing`, which preserves edge width. `min_size` is used for `skimage.morphology.remove_small_holes` after closing the image, and represents a floor area in pixels that is considered to be a true gap or hole in the object, such as when roots/hyphae cross and loop. The call to the median filter is optional but reduces small burrs that throw off the medial axis algorithm. <a href=\"http://scikit-image.org/docs/dev/api/skimage.filters.html\"> Documentation</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "fill_gaps_args = {'closing_structure'  : morphology.disk(8),  # radius of 8 pixels; fills up to 32 px wide spaces\n",
    "                  'min_hole_size'      : 300,                 # area in pixels.\n",
    "                  'median_structure'   : morphology.disk(1)}  # manhattan connectivity = 1. \n",
    "#########################################################################################\n",
    "holes_filled = pr.fill_gaps(filt, **fill_gaps_args)\n",
    "\n",
    "print(file_in[selection])\n",
    "if plot is True:\n",
    "    img = holes_filled\n",
    "    pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list], zoom_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a final morphological filtering, this time more stringent\n",
    "Because faint objects should be better connected, morphological filtering can be more stringent now.\n",
    "\n",
    "At the point, the only spurrious objects remaining should be far wider or narrower than your target objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "morphology_args_2 = {'loose_eccentricity'  : 0.5,   # This is a floor.\n",
    "                   'loose_solidity'      : 0.5,   # This is a ceiling.\n",
    "                   'strict_eccentricity' : 0.97,  # Floor.\n",
    "                   'strict_solidity'     : 0.4,   # Ceiling.\n",
    "                   'min_length'          : 125,    # Floor.\n",
    "                   'min_size'            : 125}   # Floor.\n",
    "#########################################################################################\n",
    "\n",
    "morph_filt_2 = pr.morphology_filter(holes_filled, **morphology_args_2)\n",
    "\n",
    "if plot is True:\n",
    "    img = ndimage.label(morph_filt_2)[0]\n",
    "    pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list], zoom_names, color_map=\"spectral\")\n",
    "    img = image\n",
    "    pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list], zoom_names)\n",
    "    img = [morph_filt_2, image]\n",
    "    pr.multi_image_plot(img, ['objects', 'original'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Compute skeleton\n",
    "Perform medial axis skeletonization of the image, and calculate the lenth of each ixelin that image. See <a href=\"https://github.com/pme1123/pyroots/blob/master/pyroots/skeletonization.py\"> documentation</a>.\n",
    "This function returns a dictionary with keys:\n",
    "- `\"geometry\"` - Length and diameter of each object, including background\n",
    "- `\"objects\"` - binary immage\n",
    "- `\"diameter\"` - array with medial axis diameter shown by color.\n",
    "- `\"length\"` - array with medial axis length at each pixel shown by color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# Nothing to change here\n",
    "#############################################################\n",
    "\n",
    "skel = pr.skeleton_with_distance(morph_filt_2)\n",
    "\n",
    "if plot is True:\n",
    "    print(skel['geometry'])\n",
    "    img = ndimage.label(skel['objects'])[0]\n",
    "    plt.imshow(img, cmap=\"spectral\")\n",
    "    img = skel['diameter']\n",
    "    pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list[0:3]], zoom_names[0:3], color_map = \"spectral\")\n",
    "    pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list[3:5]], zoom_names[3:5], color_map = \"spectral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter by Mean Diameter\n",
    "\n",
    "Remove objects that are narrower than a given threshold (on average), or wider than a given threshold (on average).\n",
    "\n",
    "Uses `pyroots.diameter_filter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "################################################################\n",
    "diameter_args = {'max_diameter'   : 12,\n",
    "                 'min_diameter'   : 4.5,\n",
    "                 'max_percentile' : 70,      # xx percent must not be larger than max_diameter\n",
    "                 'min_percentile' : 50,      # xx percent must not be smaller than min_diameter\n",
    "                 'pixel_level'    : False}    # remove individual pixels that don't meet max/min requirements?\n",
    "################################################################\n",
    "\n",
    "diam = pr.diameter_filter(skel, **diameter_args)\n",
    "\n",
    "if plot is True:\n",
    "    print(diam['geometry'])\n",
    "    img = ndimage.label(diam['objects'])[0]\n",
    "    plt.imshow(img, cmap=\"spectral\")\n",
    "    img = diam['diameter']\n",
    "    pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list[0:3]], zoom_names[0:3], color_map = \"spectral\")\n",
    "    pr.multi_image_plot([pr._zoom(img, **i) for i in zoom_list[3:5]], zoom_names[3:5], color_map = \"spectral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Summarize\n",
    "Summarize the objects in the image. Options center around:\n",
    "- Binning pixels by diameter class\n",
    "- Aggregating all objects.\n",
    "\n",
    "Diameter class is approximate in this case, due to the frangi filter response being correlated with object width, but also strongly related to object visibility. For more accurate diameters, try the thresholding approach of `pyroots_analysis`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################################################################\n",
    "diameter_bins = None\n",
    "image_name = \"image\"\n",
    "################################################################\n",
    "\n",
    "if diameter_bins is None:\n",
    "    summary_df = pr.summarize_geometry(diam['geometry'], image_name)\n",
    "\n",
    "else:\n",
    "    diam_out, summary_df = pr.bin_by_diameter(diam_dict['length'],\n",
    "                                              diam_dict['diameter'],\n",
    "                                              diameter_bins,\n",
    "                                              image_name)\n",
    "\n",
    "if plot is True: print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Save the parameters for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################################################################\n",
    "settings_path = dir_in\n",
    "settings_name = 'segmentation_settings_nosmooth_02-21-2017.py'  # arbitrary extension for clarity\n",
    "write = True                               # automatically update items as changed? \n",
    "write = False\n",
    "################################################################\n",
    "\n",
    "dicts = ['colors', 'frangi_args', 'threshold_args', \n",
    "         'color_args_1', 'color_args_2', 'color_args_3', 'morphology_args_1', \n",
    "         'morphology_args_2', 'hollow_args', 'fill_gaps_args', 'diameter_args', \n",
    "         'diameter_bins']\n",
    "\n",
    "if write is True:\n",
    "    path_out = os.path.join(settings_path, settings_name)\n",
    "    print(\"Wrote to: {}\".format(path_out))\n",
    "    with open(path_out, 'w') as file:\n",
    "        for i in dicts:\n",
    "            print(i + \" = \" + str(locals()[i]), file=file)\n",
    "\n",
    "    for i in dicts:\n",
    "        print(i + \" = \" + str(locals()[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run on all images\n",
    "To run this as a batch, either use the cell below with the image loop (make sure all dictionaries above are loaded into the environment) or run in the terminal. The latter option might be better for lots of threads (i.e. supercomputers). If running in this notebook, check your resource usage first and ensure you have enough RAM (~50 MB/thread for a 7MB image).\n",
    "\n",
    "## Option 1: Run In Notebook\n",
    "First, make sure the full function behaves. Then set up the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "test = True\n",
    "test=False\n",
    "# print(hollow_args)\n",
    "##############################################################\n",
    "if test is True:    \n",
    "    test_out = pr.frangi_segmentation(image, colors, frangi_args, threshold_args,\n",
    "                                      color_args_1, color_args_2, color_args_3,\n",
    "                                      morphology_args_1, morphology_args_2, hollow_args, fill_gaps_args, \n",
    "                                      diameter_args, diameter_bins, image_name=\"image\")\n",
    "\n",
    "    img = ['diameter', 'length', 'objects']\n",
    "    pr.multi_image_plot([test_out[i] for i in img], img)\n",
    "    print(test_out['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters you've loaded are:\n",
      "\n",
      "colors = {'band': 0, 'invert': False, 'colorspace': 'rgb'}\n",
      "frangi_args = {'beta2': 0.03, 'scale_step': 1, 'beta1': 0.99, 'black_ridges': True, 'scale_range': (2, 6)}\n",
      "threshold_args = {'block_size': 31, 'offset': 0.22}\n",
      "color_args_1 = {'invert': False, 'colorspace': 'rgb', 'low': 0.6, 'target_band': 2, 'percent': 55, 'high': 0.99}\n",
      "color_args_2 = {'invert': True, 'colorspace': 'hsv', 'low': 0.5, 'target_band': 1, 'percent': 30, 'high': 0}\n",
      "color_args_3 = {'invert': False, 'colorspace': 'hsv', 'low': 0.45, 'target_band': 0, 'percent': 40, 'high': 0.7}\n",
      "morphology_args_1 = {'min_length': 100, 'loose_eccentricity': 0.4, 'strict_eccentricity': 0.97, 'min_size': 100, 'loose_solidity': 0.6, 'strict_solidity': 0.4}\n",
      "morphology_args_2 = {'min_length': 125, 'loose_eccentricity': 0.5, 'strict_eccentricity': 0.97, 'min_size': 125, 'loose_solidity': 0.5, 'strict_solidity': 0.4}\n",
      "hollow_args = {'fill_kernel': 18, 'ratio': 1.5}\n",
      "fill_gaps_args = {'closing_structure': array([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "       [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "       [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "       [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "       [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "       [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8), 'min_hole_size': 300, 'median_structure': array([[0, 1, 0],\n",
      "       [1, 1, 1],\n",
      "       [0, 1, 0]], dtype=uint8)}\n",
      "diameter_args = {'max_percentile': 70, 'pixel_level': False, 'max_diameter': 12, 'min_diameter': 4.5, 'min_percentile': 50}\n",
      "diameter_bins = None\n",
      "Saving images to /home/patrick/Documents/HLD Pictures Feb 2017/image filtered/02-06-2017/Processed_No_Smoothing/NewParameters_2-22\n",
      "Saving data table to: /home/patrick/Documents/HLD Pictures Feb 2017/image filtered/02-06-2017/Processed_No_Smoothing/NewParameters_2-22/output.txt\n",
      "Done: AV1-0248.png\n",
      "Done: AX1-0647.png\n",
      "Done: AU2-0116.png\n",
      "Done: BD1-1712.png\n",
      "Done: BF2-2149.png\n",
      "Done: BC1-1505.png\n",
      "Done: BA1-1118.png\n",
      "Done: BA2-1286.png\n",
      "Done: AY1-0838.png\n",
      "Done: BB1-1359.png\n",
      "Done: BB2-1463.png\n",
      "Done: BC1-1513.png\n",
      "Done: AU1-0012.png\n",
      "Done: AZ2-1081.png\n",
      "Done: BE2-2007.png\n",
      "Done: AW2-0535.png\n",
      "Done: BC1-1490.png\n",
      "Done: BB1-1376.png\n",
      "Done: AW2-0514.png\n",
      "Done: AY1-0863.png\n",
      "Done: BA2-1270.png\n",
      "Done: BA2-1252.png\n",
      "Done: BD1-1722.png\n",
      "Done: AX2-0778.png\n",
      "Done: AY1-0843.png\n",
      "Done: BC2-1646.png\n",
      "Done: AU1-0071.png\n",
      "Done: BB1-1383.png\n",
      "Done: AZ2-1092.png\n",
      "Done: BD2-1753.png\n"
     ]
    }
   ],
   "source": [
    "import pyroots as pr\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "x = pr.frangi_image_loop(dir_in,\n",
    "                         dir_out=os.path.join(dir_in, \"NewParameters_2-22\"),\n",
    "                         extension_in=\".png\", \n",
    "                         table_out=os.path.join(dir_in, \"NewParameters_2-22\", \"output.txt\"),\n",
    "                         params=os.path.join(settings_path, settings_name),\n",
    "                         save_images=True,\n",
    "                         table_overwrite=True,\n",
    "                         threads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
